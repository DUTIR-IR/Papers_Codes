{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenNMT-tf 2.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenNMT是一个开源生态系统，用于神经机器翻译和神经序列学习。支持pytorch与tensorflow，介绍基于tensorflow2.0的openNMT 2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: OpenNMT-tf in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-addons<0.11,>=0.10 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from OpenNMT-tf) (0.10.0)\n",
      "Requirement already satisfied: ctranslate2<2,>=1.7; platform_system == \"Linux\" in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from OpenNMT-tf) (1.10.2)\n",
      "Requirement already satisfied: pyter3==0.3 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from OpenNMT-tf) (0.3)\n",
      "Requirement already satisfied: rouge<2,>=1.0 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from OpenNMT-tf) (1.0.0)\n",
      "Requirement already satisfied: pyonmttok<2,>=1.18.1; platform_system == \"Linux\" in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from OpenNMT-tf) (1.18.4)\n",
      "Requirement already satisfied: sacrebleu<2,>=1.4.9 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from OpenNMT-tf) (1.4.10)\n",
      "Requirement already satisfied: tensorflow<2.3,>=2.2 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from OpenNMT-tf) (2.2.0)\n",
      "Requirement already satisfied: pyyaml<5.4,>=5.3 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from OpenNMT-tf) (5.3.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorflow-addons<0.11,>=0.10->OpenNMT-tf) (2.9.1)\n",
      "Requirement already satisfied: six in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from ctranslate2<2,>=1.7; platform_system == \"Linux\"->OpenNMT-tf) (1.14.0)\n",
      "Requirement already satisfied: numpy in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from ctranslate2<2,>=1.7; platform_system == \"Linux\"->OpenNMT-tf) (1.18.2)\n",
      "Requirement already satisfied: portalocker in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from sacrebleu<2,>=1.4.9->OpenNMT-tf) (1.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorflow<2.3,>=2.2->OpenNMT-tf) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorflow<2.3,>=2.2->OpenNMT-tf) (3.2.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorflow<2.3,>=2.2->OpenNMT-tf) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorflow<2.3,>=2.2->OpenNMT-tf) (2.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorflow<2.3,>=2.2->OpenNMT-tf) (0.9.0)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorflow<2.3,>=2.2->OpenNMT-tf) (2.2.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorflow<2.3,>=2.2->OpenNMT-tf) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorflow<2.3,>=2.2->OpenNMT-tf) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorflow<2.3,>=2.2->OpenNMT-tf) (3.11.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorflow<2.3,>=2.2->OpenNMT-tf) (1.27.2)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorflow<2.3,>=2.2->OpenNMT-tf) (0.3.3)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorflow<2.3,>=2.2->OpenNMT-tf) (1.12.1)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorflow<2.3,>=2.2->OpenNMT-tf) (1.4.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorflow<2.3,>=2.2->OpenNMT-tf) (0.34.2)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorflow<2.3,>=2.2->OpenNMT-tf) (2.10.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.3,>=2.2->OpenNMT-tf) (1.11.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.3,>=2.2->OpenNMT-tf) (46.1.1.post20200323)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.3,>=2.2->OpenNMT-tf) (3.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.3,>=2.2->OpenNMT-tf) (2.21.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.3,>=2.2->OpenNMT-tf) (1.6.0.post3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.3,>=2.2->OpenNMT-tf) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.3,>=2.2->OpenNMT-tf) (1.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3,>=2.2->OpenNMT-tf) (0.2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3,>=2.2->OpenNMT-tf) (4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3,>=2.2->OpenNMT-tf) (4.0.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3,>=2.2->OpenNMT-tf) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3,>=2.2->OpenNMT-tf) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3,>=2.2->OpenNMT-tf) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3,>=2.2->OpenNMT-tf) (2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3,>=2.2->OpenNMT-tf) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3,>=2.2->OpenNMT-tf) (0.4.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/dutir_2t/wangchenguang/anaconda3/envs/sunyi/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3,>=2.2->OpenNMT-tf) (3.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install OpenNMT-tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opennmt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['which group are you in ?', 'where you are ?']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('src.txt', 'r') as f:\n",
    "    src_data = f.read().split('\\n')[:-1]\n",
    "src_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the search group .', 'i am in ir .']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('tgt.txt', 'r') as f:\n",
    "    tgt_data = f.read().split('\\n')[:-1]\n",
    "tgt_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# package opennmt.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 字典构建 opennmt.data.Vocab(special_tokens=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = ['<s>', '</s>', '<unk>', '<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '</s>', '<unk>', '<pad>']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = opennmt.data.Vocab(special_tokens)\n",
    "vocab.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '</s>',\n",
       " '<unk>',\n",
       " '<pad>',\n",
       " 'which',\n",
       " 'group',\n",
       " 'are',\n",
       " 'you',\n",
       " 'in',\n",
       " '?',\n",
       " 'where']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.add_from_text('src.txt')\n",
    "vocab.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '</s>',\n",
       " '<unk>',\n",
       " '<pad>',\n",
       " 'which',\n",
       " 'group',\n",
       " 'are',\n",
       " 'you',\n",
       " 'in',\n",
       " '?',\n",
       " 'where',\n",
       " 'the',\n",
       " 'search',\n",
       " '.',\n",
       " 'i',\n",
       " 'am',\n",
       " 'ir']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.add_from_text('tgt.txt')\n",
    "vocab.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup('group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'group'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '</s>', '<unk>', '<pad>', 'group', 'are', 'you', 'in', '?', '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.prune(max_size=0, min_frequency=2).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.serialize('vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "</s>\n",
      "<unk>\n",
      "<pad>\n",
      "which\n",
      "group\n",
      "are\n",
      "you\n",
      "in\n",
      "?\n",
      "where\n",
      "the\n",
      "search\n",
      ".\n",
      "i\n",
      "am\n",
      "ir\n"
     ]
    }
   ],
   "source": [
    "with open('vocab.txt') as f:\n",
    "    for w in f.readlines():\n",
    "        print(w[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据噪声 noise = opennmt.data.WordOmission(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'which', b'group', b'are', b'you', b'?'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = opennmt.data.WordOmission(1)\n",
    "noise(tf.constant(src_data[0].split())).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'which', b'group', b'in', b'?'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = opennmt.data.WordOmission(2)\n",
    "noise(tf.constant(src_data[0].split())).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据噪声 opennmt.data.WordDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'which', b'group', b'are', b'you', b'in'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = opennmt.data.WordDropout(0.5)\n",
    "noise(tf.constant(src_data[0].split())).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'which'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = opennmt.data.WordDropout(0.9)\n",
    "noise(tf.constant(src_data[0].split())).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'group', b'are', b'in'], [b'where', b'you', b'are', b'?']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = opennmt.data.WordDropout(0.2)\n",
    "src_data = [noise(tf.constant(line.split())).numpy().tolist() for line in src_data]\n",
    "src_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'the', b'search', b'group', b'.'], [b'am', b'in', b'ir', b'.']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_data = [noise(tf.constant(line.split())).numpy().tolist() for line in tgt_data]\n",
    "tgt_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 6, 8], [10, 7, 6, 9]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_id = [[vocab.lookup(word) if word in vocab else \n",
    "           vocab.lookup('<unk>') for word in line] for line in src_data]\n",
    "src_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11, 12, 5, 13], [15, 8, 16, 13]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_id = [[vocab.lookup(word) if word in vocab else \n",
    "           vocab.lookup('<unk>') for word in line] for line in tgt_data]\n",
    "tgt_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package opennmt.encoders\n",
    "##### class opennmt.encoders.LSTMEncoder(num_layers, num_units, bidirectional=False, residual_connections=False, dropout=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  3,  3,  3,  3,  3,  3,  5,  6,  8],\n",
       "       [ 3,  3,  3,  3,  3,  3, 10,  7,  6,  9]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 10\n",
    "pad_src_id = tf.keras.preprocessing.sequence.pad_sequences(src_id, value = vocab.lookup('<pad>'), \n",
    "                                                       maxlen = max_len)\n",
    "src_seq_len = [len(x) for x in src_data]\n",
    "pad_src_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  3,  3,  3,  3,  3, 11, 12,  5, 13],\n",
       "       [ 3,  3,  3,  3,  3,  3, 15,  8, 16, 13]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 10\n",
    "pad_tgt_id = tf.keras.preprocessing.sequence.pad_sequences(tgt_id, value = vocab.lookup('<pad>'), \n",
    "                                                       maxlen = max_len)\n",
    "tgt_seq_len = [len(x) for x in tgt_data]\n",
    "pad_tgt_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 10, 20])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dim = 20\n",
    "pad_src_emb = tf.keras.layers.Embedding(vocab.size, emb_dim, input_length=10)(pad_src_id)\n",
    "pad_src_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 10, 15])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = opennmt.encoders.LSTMEncoder(1, 15)\n",
    "outputs, states, sequence_length = enc(pad_src_emb, src_seq_len)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(15,), dtype=float32, numpy=\n",
       "array([ 0.00263265,  0.00270151, -0.00246869, -0.01116184,  0.0044781 ,\n",
       "       -0.00544795, -0.00939717, -0.00074116,  0.00283719,  0.00317579,\n",
       "       -0.0209918 , -0.00500038,  0.00414584, -0.00178641,  0.00918154],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor: shape=(2, 15), dtype=float32, numpy=\n",
       "  array([[ 0.00263265,  0.00270151, -0.00246869, -0.01116184,  0.0044781 ,\n",
       "          -0.00544795, -0.00939717, -0.00074116,  0.00283719,  0.00317579,\n",
       "          -0.0209918 , -0.00500038,  0.00414584, -0.00178641,  0.00918154],\n",
       "         [ 0.00260052,  0.0035042 , -0.00318885, -0.01382197,  0.00480902,\n",
       "          -0.00694631, -0.01076731, -0.00148092,  0.00358938,  0.00395388,\n",
       "          -0.02524526, -0.00543948,  0.00530553, -0.00180258,  0.00998819]],\n",
       "        dtype=float32)>,\n",
       "  <tf.Tensor: shape=(2, 15), dtype=float32, numpy=\n",
       "  array([[ 0.00526918,  0.00541064, -0.00498785, -0.02257553,  0.00897897,\n",
       "          -0.01069824, -0.01888357, -0.00147908,  0.00574807,  0.0063295 ,\n",
       "          -0.04177443, -0.00991749,  0.0082333 , -0.00360373,  0.01835097],\n",
       "         [ 0.00520667,  0.00702028, -0.00644645, -0.02795127,  0.00965023,\n",
       "          -0.01363943, -0.02165095, -0.00295668,  0.00727191,  0.00786874,\n",
       "          -0.0502619 , -0.01078528,  0.01052854, -0.00363642,  0.0199643 ]],\n",
       "        dtype=float32)>),)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 15), dtype=float32, numpy=\n",
       "array([[ 0.00263265,  0.00270151, -0.00246869, -0.01116184,  0.0044781 ,\n",
       "        -0.00544795, -0.00939717, -0.00074116,  0.00283719,  0.00317579,\n",
       "        -0.0209918 , -0.00500038,  0.00414584, -0.00178641,  0.00918154],\n",
       "       [ 0.00260052,  0.0035042 , -0.00318885, -0.01382197,  0.00480902,\n",
       "        -0.00694631, -0.01076731, -0.00148092,  0.00358938,  0.00395388,\n",
       "        -0.02524526, -0.00543948,  0.00530553, -0.00180258,  0.00998819]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ConvEncoder\n",
    "* GNMTEncoder\n",
    "* LSTMEncoder \n",
    "* MeanEncoder \n",
    "* SelfAttentionEncoder \n",
    "* PositionEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class opennmt.encoders.ParallelEncoder(encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc1 = opennmt.encoders.LSTMEncoder(1, 20)\n",
    "enc2 = opennmt.encoders.LSTMEncoder(1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(40,), dtype=float32, numpy=\n",
       "array([ 4.27721580e-03, -1.23676815e-04,  3.24125448e-03, -1.46875530e-03,\n",
       "       -1.34765105e-02, -1.64073566e-03,  1.74806651e-03, -6.06455002e-03,\n",
       "       -8.01201910e-03, -6.79677445e-03,  1.38312075e-02, -4.11572959e-03,\n",
       "        2.75489129e-03, -3.81474989e-03, -9.28935595e-03, -2.24214066e-02,\n",
       "       -1.05688795e-02,  4.38976288e-03, -1.19652329e-02, -9.21650697e-03,\n",
       "        8.09337478e-03,  3.73086799e-03,  5.36764553e-03, -9.33439191e-03,\n",
       "        1.46115869e-02, -8.60170182e-03,  6.91711390e-03,  7.95671996e-03,\n",
       "        3.59884161e-03, -9.58624575e-03, -1.82081982e-02,  2.73429730e-04,\n",
       "        7.97878113e-03,  1.07945474e-02, -1.93337929e-02,  1.48923192e-02,\n",
       "        3.65795591e-03,  4.78065666e-03, -3.62304017e-05,  1.04617607e-02],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_enc = opennmt.encoders.ParallelEncoder([\n",
    "    enc1,\n",
    "    enc2,\n",
    "], outputs_reducer = opennmt.layers.ConcatReducer())\n",
    "outputs, states, sequence_length = p_enc(pad_src_emb, src_seq_len)\n",
    "outputs[0,src_seq_len[0]-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(40,), dtype=float32, numpy=\n",
       "array([ 4.27721580e-03, -1.23676815e-04,  3.24125448e-03, -1.46875530e-03,\n",
       "       -1.34765105e-02, -1.64073566e-03,  1.74806651e-03, -6.06455002e-03,\n",
       "       -8.01201910e-03, -6.79677445e-03,  1.38312075e-02, -4.11572959e-03,\n",
       "        2.75489129e-03, -3.81474989e-03, -9.28935595e-03, -2.24214066e-02,\n",
       "       -1.05688795e-02,  4.38976288e-03, -1.19652329e-02, -9.21650697e-03,\n",
       "        8.09337478e-03,  3.73086799e-03,  5.36764553e-03, -9.33439191e-03,\n",
       "        1.46115869e-02, -8.60170182e-03,  6.91711390e-03,  7.95671996e-03,\n",
       "        3.59884161e-03, -9.58624575e-03, -1.82081982e-02,  2.73429730e-04,\n",
       "        7.97878113e-03,  1.07945474e-02, -1.93337929e-02,  1.48923192e-02,\n",
       "        3.65795591e-03,  4.78065666e-03, -3.62304017e-05,  1.04617607e-02],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1, _, _ = enc1(pad_src_emb, src_seq_len)\n",
    "outputs2, _, _ = enc2(pad_src_emb, src_seq_len)\n",
    "tf.concat([outputs1, outputs2], axis = -1)[0,src_seq_len[0]-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.0188968 , 0.00430593],\n",
       "       [0.02246414, 0.00638116]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs, state, _ = enc(pad_src_emb, src_seq_len)\n",
    "logits = opennmt.layers.Dense(2)(state[0][0])\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package opennmt.models\n",
    "\n",
    "* opennmt.models.GPT2Small\n",
    "* opennmt.models.LanguageModel\n",
    "* opennmt.models.LstmCnnCrfTagger\n",
    "* opennmt.models.SequenceClassifier\n",
    "* opennmt.models.SequenceGenerator\n",
    "* opennmt.models.SequenceTagger\n",
    "* opennmt.models.SequenceToSequence\n",
    "* opennmt.models.Transformer\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package opennmt.utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* opennmt.utils.BLEUScorer\n",
    "* opennmt.utils.BeamSearch\n",
    "* opennmt.utils.GreedySearch\n",
    "* opennmt.utils.PRFScorer\n",
    "* opennmt.utils.ROUGEScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
