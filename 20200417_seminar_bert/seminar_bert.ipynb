{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code For Model Compressing：Pruning and Distilling\n",
    "\n",
    "                                                        姓名：岳天驰\n",
    "                                                        导师：张绍武\n",
    "                                                        - 2020年4月17日\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Overview of BERT模型压缩](http://mitchgordon.me/machine/learning/2019/11/18/all-the-ways-to-compress-BERT.html)\n",
    "\n",
    "![title](img/f0.png)\n",
    "![title](img/f1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1： 剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>非结构化剪枝：考虑每个权重，删除不重要的参数；也称为稀疏剪枝</h3>\n",
       "<img src='img/f2.png', width=400>\n",
       "<h3>结构化剪枝：直接去掉整个神经元的结构化信息；</h3>\n",
       "<img src='img/f3.png', width=400>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<h3>非结构化剪枝：考虑每个权重，删除不重要的参数；也称为稀疏剪枝</h3>\n",
    "<img src='img/f2.png', width=400>\n",
    "<h3>结构化剪枝：直接去掉整个神经元的结构化信息；</h3>\n",
    "<img src='img/f3.png', width=400>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 剪枝过程\n",
    "- one-shot剪枝：\n",
    "    - train -> evaluate-> prune -> finetune -> stop\n",
    "- Iteration:\n",
    "    - train -> evaluate -> prune -> finetune -> if continue return step2 else stop\n",
    "    \n",
    "    \n",
    "## [Rethinking the Value of Network Pruning](https://arxiv.org/pdf/1810.05270.pdf)          ICLR2019\n",
    "- https://github.com/Eric-mingjie/rethinking-network-pruning\n",
    "- 猜想：\n",
    "    - 对于如左图可以预定义的架构，可以直接随机初始化训练小模型。\n",
    "    - 对于如右图无预定义的架构, 随机初始化训练剪枝后的模型可以实现与微调一样的效果\n",
    "![title](img/f9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaseModel VGG\n",
    "![title](img/f4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "defaultcfg = {\n",
    "    11 : [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n",
    "    13 : [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n",
    "    16 : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512],\n",
    "    19 : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512],\n",
    "}\n",
    "\n",
    "class vgg(nn.Module):\n",
    "    def __init__(self, depth=19, init_weights=True, cfg=None):\n",
    "        super(vgg, self).__init__()\n",
    "        if cfg is None:\n",
    "            cfg = defaultcfg[depth]\n",
    "\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.feature = self.make_layers(cfg, True)\n",
    "        self.classifier = nn.Sequential(\n",
    "              nn.Linear(cfg[-1], 512),\n",
    "              nn.BatchNorm1d(512),\n",
    "              nn.ReLU(inplace=True),\n",
    "              nn.Linear(512, 10)\n",
    "            )\n",
    "\n",
    "    def make_layers(self, cfg, batch_norm=False):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1, bias=False)\n",
    "                if batch_norm:\n",
    "                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "                else:\n",
    "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "                in_channels = v\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "        x = nn.AvgPool2d(2)(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y = self.classifier(x)\n",
    "        return y\n",
    "\n",
    "\n",
    "base_model = vgg(cfg=defaultcfg[19])\n",
    "\n",
    "print(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Pruning Filters for Efficient ConvNets](https://arxiv.org/pdf/1608.08710.pdf) ICLR 2017 \n",
    "- 结构化剪枝，裁剪每一个卷积层的权值小的filter\n",
    "![title](img/f5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64, 3, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 例如对于3*3的2d卷积，in_channels=64, out_channels=1\n",
    "# 该层参数权重是(128,64,3,3),计算每个64,3,3的权重和，就是128个数，进行排序，然后裁掉较小的部分，保留剩下的 \n",
    "# 比如可以裁剪成(64,64,3,3),那么该层的输出就减少了。下层的输入就少了。\n",
    "conv = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3))\n",
    "conv.weight.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结构化剪枝关键部分伪代码片段\n",
    "cfg = [32, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 256, 256, 256, 'M', 256, 256, 256]\n",
    "\n",
    "cfg_mask = []\n",
    "layer_id = 0\n",
    "# 对于每个卷积层，计算每个filter的参数和，然后排序，然后利用mask进行选择。\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        out_channels = m.weight.data.shape[0]\n",
    "        if out_channels == cfg[layer_id]:\n",
    "            cfg_mask.append(torch.ones(out_channels))\n",
    "            layer_id += 1\n",
    "            continue\n",
    "        weight_copy = m.weight.data.abs().clone()\n",
    "        weight_copy = weight_copy.cpu().numpy()\n",
    "        # 首先计算每个filter的权值和，一共128个，然后进行排序\n",
    "        L1_norm = np.sum(weight_copy, axis=(1, 2, 3))\n",
    "        arg_max = np.argsort(L1_norm)\n",
    "        arg_max_rev = arg_max[::-1][:cfg[layer_id]]\n",
    "        assert arg_max_rev.size == cfg[layer_id], \"size of arg_max_rev not correct\"\n",
    "        mask = torch.zeros(out_channels)\n",
    "        # mask 只有对大权值的设置为1\n",
    "        mask[arg_max_rev.tolist()] = 1\n",
    "        cfg_mask.append(mask)\n",
    "        layer_id += 1\n",
    "\n",
    "\n",
    "newmodel = vgg(dataset=args.dataset, cfg=cfg)\n",
    "\n",
    "# 遍历原模型和新模型。将原模型的copy进去。    \n",
    "start_mask = torch.ones(3)\n",
    "layer_id_in_cfg = 0\n",
    "end_mask = cfg_mask[layer_id_in_cfg]\n",
    "for [m0, m1] in zip(model.modules(), newmodel.modules()):\n",
    "    elif isinstance(m0, nn.Conv2d):\n",
    "        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "        print('In shape: {:d}, Out shape {:d}.'.format(idx0.size, idx1.size))\n",
    "        if idx0.size == 1:\n",
    "            idx0 = np.resize(idx0, (1,))\n",
    "        if idx1.size == 1:\n",
    "            idx1 = np.resize(idx1, (1,))\n",
    "        # 将原模型的权重拷贝到新模型中，权重的in_channels和out_channels要改变\n",
    "        w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "        w1 = w1[idx1.tolist(), :, :, :].clone()\n",
    "        m1.weight.data = w1.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [The Lottery Ticket Hypothesis:finding sparse, Trainable Neural Networks](https://arxiv.org/pdf/1803.03635.pdf)  ICLR 2019\n",
    "- 一个随机初始化的大型神经网络包含一个初始化的子网络，在单独训练时，最多经过相同的迭代次数，可以达到和原始网络一样的测试准确率。\n",
    "- 将一个复杂网络的所有参数当做奖池，上述一组子参数对应的子网络就是中奖彩票。\n",
    "- 一个密集的前馈神经网络 f(x;θ)，其中初始化参数 θ,当在训练集上用随机梯度下降时，f 可以在 j 次迭代后达到损失 l 和准确率 a。\n",
    "- 考虑对参数θ作用一个 01 mask矩阵，在相同的数据集上训练 f(x;m⊙θ), f 在 j' 次迭代后达到损失 l' 和准确率 a'。\n",
    "- 彩票假设指出存在 m, 使得 j'<=j (训练时间更快), a'>=a (准确率更高), ||m||_0 << |θ| (更少的参数)。\n",
    "-![title](img/f9.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-27-da4653771bab>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-27-da4653771bab>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    - threshold 0.5\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 例如对于3*3的2d卷积，in_channels=64, out_channels=1\n",
    "# 该层参数权重是(128,64,3,3),计算所有权重的值，然后进行排序，选择一个阈值，将小与阈值的部分裁掉\n",
    "\"\"\"\n",
    "- weight [0.1,0.8,\n",
    "          0.7,0.2]\n",
    "- threshold 0.5\n",
    "- mask [0,1,\n",
    "       1,0]\n",
    "- new_weight = mask*weight\n",
    "\"\"\"\n",
    "\n",
    "# 非结构化剪枝代码片段\n",
    "\n",
    "# pruning \n",
    "total = 0\n",
    "# 首先统计一共有多少参数，然后排序。 根据裁剪比例选择阈值\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        total += m.weight.data.numel()\n",
    "conv_weights = torch.zeros(total)\n",
    "index = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        size = m.weight.data.numel()\n",
    "        conv_weights[index:(index+size)] = m.weight.data.view(-1).abs().clone()\n",
    "        index += size\n",
    "y, i = torch.sort(conv_weights)\n",
    "thre_index = int(total * args.percent)\n",
    "thre = y[thre_index]\n",
    "pruned = 0\n",
    "print('Pruning threshold: {}'.format(thre))\n",
    "zero_flag = False\n",
    "\n",
    "# 遍历每个modules,对卷积的权重进行修改，设定mask矩阵与weight同大小，如果该权重小于，则为0.\n",
    "for k, m in enumerate(model.modules()):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        weight_copy = m.weight.data.abs().clone()\n",
    "        mask = weight_copy.gt(thre).float().cuda()\n",
    "        pruned = pruned + mask.numel() - torch.sum(mask)\n",
    "        m.weight.data.mul_(mask)\n",
    "        if int(torch.sum(mask)) == 0:\n",
    "            zero_flag = True\n",
    "        print('layer index: {:d} \\t total params: {:d} \\t remaining params: {:d}'.\n",
    "            format(k, mask.numel(), int(torch.sum(mask))))\n",
    "print('Total conv params: {}, Pruned conv params: {}, Pruned ratio: {}'.format(total, pruned, pruned/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------\n",
    "# 2： 蒸馏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Patient Knowledge Distillation for BERT Model Compression](https://arxiv.org/pdf/1908.09355.pdf) - EMNLP2019  微软\n",
    "- https://github.com/intersun/PKD-for-BERT-Model-Compression\n",
    "\n",
    "## [Tiny BERT](https://arxiv.org/pdf/1909.10351.pdf)   - ICLR2020 拒稿 华为\n",
    "- https://github.com/huawei-noah/Pretrained-Language-Model\n",
    "![title](img/f8.png)\n",
    "\n",
    "- TinyBERT 的 transformer 蒸馏采用隔 k 层蒸馏的方式。\n",
    "- 举个例子，teacher BERT 一共有 12 层，若是设置 student BERT 为 4 层，就是每隔 3 层计算一个 transformer loss. \n",
    "- 映射函数为 g(m) = 3 * m, m 为 student encoder 层数。\n",
    "- 具体对应为 student 第 1 层 transformer 对应 teacher 第 3 层，第 2 层对应第 6 层，第 3 层对应第 9 层，第 4 层对应第 12 层。\n",
    "- 每一层的 transformer loss 又分为两部分组成，attention based distillation 和 hidden states based distillation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建student_model和 teacher_model. 将attention_weights 和 hidden_states对应，算loss\n",
    "student_model = TinyBertForPreTraining.from_scratch(args.student_model)\n",
    "teacher_model = BertModel.from_pretrained(args.teacher_model)\n",
    "student_atts, student_reps = student_model(input_ids, segment_ids, input_mask)\n",
    "teacher_reps, teacher_atts, _ = teacher_model(input_ids, segment_ids, input_mask)\n",
    "teacher_reps = [teacher_rep.detach() for teacher_rep in teacher_reps]  # speedup 1.5x\n",
    "teacher_atts = [teacher_att.detach() for teacher_att in teacher_atts]\n",
    "\n",
    "teacher_layer_num = len(teacher_atts)\n",
    "student_layer_num = len(student_atts)\n",
    "assert teacher_layer_num % student_layer_num == 0\n",
    "layers_per_block = int(teacher_layer_num / student_layer_num)\n",
    "new_teacher_atts = [teacher_atts[i * layers_per_block + layers_per_block - 1]\n",
    "                    for i in range(student_layer_num)]\n",
    "\n",
    "for student_att, teacher_att in zip(student_atts, new_teacher_atts):\n",
    "    student_att = torch.where(student_att <= -1e2, torch.zeros_like(student_att).to(device),\n",
    "                              student_att)\n",
    "    teacher_att = torch.where(teacher_att <= -1e2, torch.zeros_like(teacher_att).to(device),\n",
    "                              teacher_att)\n",
    "    att_loss += loss_mse(student_att, teacher_att)\n",
    "\n",
    "new_teacher_reps = [teacher_reps[i * layers_per_block] for i in range(student_layer_num + 1)]\n",
    "new_student_reps = student_reps\n",
    "\n",
    "for student_rep, teacher_rep in zip(new_student_redps, new_teacher_reps):\n",
    "    rep_loss += loss_mse(student_rep, teacher_rep)\n",
    "\n",
    "loss = att_loss + rep_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [BERT-of-Theseus: Compressing BERT by Progressive Module Replacing](https://arxiv.org/pdf/2002.02925.pdf)  - ARXIV 2020.02 微软\n",
    "-  https://github.com/JetRunner/BERT-of-Theseus\n",
    "![title](img/f6.png)\n",
    "- Pmodel是原模型 ,Smodel是压缩后的模型。如果要压缩一半的层数，原始bert-base为12层，压缩后为6层。\n",
    "- Smodel的第i个module为scc_i，0<=i<6,每个module包含一个transformer layer。\n",
    "- 将Pmodel的12层分隔成6个module，每个module包含两个transformer layers，得到 Prdi,0<=i<6\n",
    "- 可以将scc_i和prd_i建立一对一的映射关系。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "self.layer = nn.ModuleList([BertLayer(config) for _ in range(self.prd_n_layer)])\n",
    "self.scc_layer = nn.ModuleList([BertLayer(config) for _ in range(self.scc_n_layer)])\n",
    "# 只需要改training阶段的BertEncoder的layers组合部分。\n",
    "def forward(self, hidden_states, attention_mask=None, head_mask=None, encoder_hidden_states=None,\n",
    "            encoder_attention_mask=None):\n",
    "    all_hidden_states = ()\n",
    "    all_attentions = ()\n",
    "    if self.training:\n",
    "        inference_layers = []\n",
    "        for i in range(self.scc_n_layer):\n",
    "            # 根据概率去选择替换还是不替换\n",
    "            if self.bernoulli.sample() == 1:  # REPLACE\n",
    "                inference_layers.append(self.scc_layer[i])\n",
    "            else:  # KEEP the original\n",
    "                for offset in range(self.compress_ratio):\n",
    "                    inference_layers.append(self.layer[i * self.compress_ratio + offset])\n",
    "\n",
    "    else:  # inference with compressed model\n",
    "        inference_layers = self.scc_layer\n",
    "        \n",
    "#初始化\n",
    "scc_n_layer = model.bert.encoder.scc_n_layer\n",
    "model.bert.encoder.scc_layer = nn.ModuleList([deepcopy(model.bert.encoder.layer[ix]) for ix in range(scc_n_layer)])\n",
    "\n",
    "# 概率替换策略\n",
    "class LinearReplacementScheduler:\n",
    "    def __init__(self, bert_encoder: BertEncoder, base_replacing_rate, k):\n",
    "        self.bert_encoder = bert_encoder\n",
    "        self.base_replacing_rate = base_replacing_rate\n",
    "        self.step_counter = 0\n",
    "        self.k = k\n",
    "        self.bert_encoder.set_replacing_rate(base_replacing_rate)\n",
    "\n",
    "    def step(self):\n",
    "        self.step_counter += 1\n",
    "        current_replacing_rate = min(self.k * self.step_counter + self.base_replacing_rate, 1.0)\n",
    "        self.bert_encoder.set_replacing_rate(current_replacing_rate)\n",
    "        return current_replacing_rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
